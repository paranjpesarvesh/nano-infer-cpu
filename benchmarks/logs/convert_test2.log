Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...
Downloading TinyLlama/TinyLlama-1.1B-Chat-v1.0 from HuggingFace...
Model Config: {'vocab_size': 32000, 'dim': 2048, 'layers': 22, 'n_heads': 32, 'n_kv_heads': 4, 'hidden_dim': 5632}
Packing Embedding Layer...
   Processed Layer 0/22...
   Processed Layer 5/22...
   Processed Layer 10/22...
   Processed Layer 15/22...
   Processed Layer 20/22...
Packing Final Layers...
Quantizing weights (Int8 Per-Channel)...
   Quantized tensor 0/201...
   Quantized tensor 10/201...
   Quantized tensor 20/201...
   Quantized tensor 30/201...
   Quantized tensor 40/201...
   Quantized tensor 50/201...
   Quantized tensor 60/201...
   Quantized tensor 70/201...
   Quantized tensor 80/201...
   Quantized tensor 90/201...
   Quantized tensor 100/201...
   Quantized tensor 110/201...
   Quantized tensor 120/201...
   Quantized tensor 130/201...
   Quantized tensor 140/201...
   Quantized tensor 150/201...
   Quantized tensor 160/201...
   Quantized tensor 170/201...
   Quantized tensor 180/201...
   Quantized tensor 190/201...
   Quantized tensor 200/201...
Writing to models/tinyllama.nano...
Success! Wrote 1050.72 MB of tensor data.
Conversion Complete! Model saved to models/tinyllama.nano
